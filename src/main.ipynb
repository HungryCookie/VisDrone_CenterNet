{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import _init_paths\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from opts import opts\n",
    "from models.model import create_model, load_model, save_model\n",
    "from models.data_parallel import DataParallel\n",
    "from logger import Logger\n",
    "from datasets.dataset_factory import get_dataset\n",
    "from trains.train_factory import train_factory\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(opt.seed)\n",
    "torch.backends.cudnn.benchmark = not opt.not_cuda_benchmark and not opt.test\n",
    "Dataset = get_dataset(opt.dataset, opt.task)\n",
    "opt = opts().update_dataset_info_and_set_heads(opt, Dataset)\n",
    "print(opt)\n",
    "\n",
    "logger = Logger(opt)\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = opt.gpus_str\n",
    "opt.device = torch.device('cuda' if opt.gpus[0] >= 0 else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(opt.arch, opt.heads, opt.head_conv)\n",
    "optimizer = torch.optim.Adam(model.parameters(), opt.lr)\n",
    "start_epoch = 0\n",
    "if opt.load_model != '':\n",
    "    model, optimizer, start_epoch = load_model(\n",
    "      model, opt.load_model, optimizer, opt.resume, opt.lr, opt.lr_step)\n",
    "\n",
    "Trainer = train_factory[opt.task]\n",
    "trainer = Trainer(opt, model, optimizer)\n",
    "trainer.set_device(opt.gpus, opt.chunk_sizes, opt.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "  Dataset(opt, 'val'), \n",
    "  batch_size=1, \n",
    "  shuffle=False,\n",
    "  num_workers=1,\n",
    "  pin_memory=True\n",
    ")\n",
    "\n",
    "if opt.test:\n",
    "    _, preds = trainer.val(0, val_loader)\n",
    "    val_loader.dataset.run_eval(preds, opt.save_dir)\n",
    "else:\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "      Dataset(opt, 'train'), \n",
    "      batch_size=opt.batch_size, \n",
    "      shuffle=True,\n",
    "      num_workers=opt.num_workers,\n",
    "      pin_memory=True,\n",
    "      drop_last=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = 1e10\n",
    "for epoch in range(start_epoch + 1, opt.num_epochs + 1):\n",
    "    mark = epoch if opt.save_all else 'last'\n",
    "    log_dict_train, _ = trainer.train(epoch, train_loader)\n",
    "    logger.write('epoch: {} |'.format(epoch))\n",
    "    for k, v in log_dict_train.items():\n",
    "        logger.scalar_summary('train_{}'.format(k), v, epoch)\n",
    "        logger.write('{} {:8f} | '.format(k, v))\n",
    "    if opt.val_intervals > 0 and epoch % opt.val_intervals == 0:\n",
    "        save_model(os.path.join(opt.save_dir, 'model_{}.pth'.format(mark)), \n",
    "                 epoch, model, optimizer)\n",
    "        with torch.no_grad():\n",
    "            log_dict_val, preds = trainer.val(epoch, val_loader)\n",
    "        for k, v in log_dict_val.items():\n",
    "            logger.scalar_summary('val_{}'.format(k), v, epoch)\n",
    "            logger.write('{} {:8f} | '.format(k, v))\n",
    "        if log_dict_val[opt.metric] < best:\n",
    "            best = log_dict_val[opt.metric]\n",
    "            save_model(os.path.join(opt.save_dir, 'model_best.pth'), \n",
    "                       epoch, model)\n",
    "    else:\n",
    "        save_model(os.path.join(opt.save_dir, 'model_last.pth'), \n",
    "                 epoch, model, optimizer)\n",
    "    logger.write('\\n')\n",
    "    if epoch in opt.lr_step:\n",
    "        save_model(os.path.join(opt.save_dir, 'model_{}.pth'.format(epoch)), \n",
    "                 epoch, model, optimizer)\n",
    "        lr = opt.lr * (0.1 ** (opt.lr_step.index(epoch) + 1))\n",
    "        print('Drop LR to', lr)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "logger.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
